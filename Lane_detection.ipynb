{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from tensorflow.python.keras import losses\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from util import losses, custom_data_generator, metrics \n",
    "from keras.utils import multi_gpu_model\n",
    "from models import model_loader\n",
    "import datetime\n",
    "from processing import abs_sobel_thresh\n",
    "from processing import mag_threshold\n",
    "from processing import *\n",
    "from util import custom_data_generator as data_util\n",
    "from models.common import lanenet_wavelet\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "# set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "batch_size =30\n",
    "is_train =  False\n",
    "# model_name = 'lanenet'\n",
    "image_width,image_height = 512,512\n",
    "channeles = 3\n",
    "# checkpoint_name = \"checkpoint_lanenet\"\n",
    "one_hot_label= False\n",
    "data_aug = False\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = \"./checkpoints/%s/\"%(checkpoint_name)\n",
    "\n",
    "# path = '../../../Lane_Data/GAN_merged_v4/train_h'\n",
    "# imgPath = './full_img.png'/\n",
    "path = '/home/beemap/Documents/cesar-workspace/Lane_Data/Mix_dataset_full_v2/val'\n",
    "val_inputs_path = path +\"/\"\n",
    "val_masks_path = path +\"_labels/\"\n",
    "\n",
    "\n",
    "val_samples = glob.glob(val_inputs_path + \"*\")\n",
    "\n",
    "print(\"Validation samples = %s\\n\\n\"%(len(val_samples)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(val_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(val_samples[-1], -1)\n",
    "img = cv2.imread(imgPa)\n",
    "#img = cv2.resize(img, (256, 256))\n",
    "img.shape\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = './full_img.png'\n",
    "BigImg = cv2.imread(imgPath, -1)\n",
    "BigImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskPath = './mask.png'\n",
    "BigMask = cv2.imread(maskPath, 0)\n",
    "index = BigMask == 0\n",
    "BigImg[index] = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = './predictions_lanes/'\n",
    "if not os.path.isdir(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_name = \"checkpoint_lanenet\"\n",
    "checkpoint_name = \"Mix_dataset_full_v2_lanenet\"\n",
    "\n",
    "model_name = 'lanenet'\n",
    "checkpoint_dir = \"./checkpoints/%s/\"%(checkpoint_name)\n",
    "\n",
    "if is_train:   \n",
    "    \n",
    "     print(\"Training .....\")\n",
    "\n",
    "else:\n",
    "    print(\"Loading Model .... \",checkpoint_dir)\n",
    "    json_file = open(checkpoint_dir+model_name+\".json\", 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(\"./checkpoints/%s/%s_weights_90.h5\"%(checkpoint_name,model_name))\n",
    "    #asd\n",
    "#     print(checkpoint_path)\n",
    "#     files = glob.glob('/home/beemap/Documents/noor-workspace/Semantic-Segmentation-Suite/airbus/train/*.png')\n",
    "#     accu = []\n",
    "#     BG_IU, BD_IU, BG_P, BD_P = metrics.calculate_IoU_Per_Epoch(model,val_inputs_path,val_masks_path,checkpoint_dir,1,False)\n",
    "#     for i in range(50):\n",
    "#         gen = next(train_generator)\n",
    "#     gen = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_pipeline(img, mask):\n",
    "    \n",
    "    ind = (mask == 0)\n",
    "    img[ind] = 0\n",
    "    img_copy = cv.GaussianBlur(img, (3, 3), 0)\n",
    "    #img_copy = np.copy(img)\n",
    "    \n",
    "    # color channels\n",
    "    s_binary = hls_select(img_copy, sthresh=(140, 255), lthresh=(120, 255))\n",
    "    #red_binary = red_select(img_copy, thresh=(200,255))\n",
    "    \n",
    "    # Sobel x\n",
    "    x_binary = abs_sobel_thresh(img_copy,thresh=(25, 200))\n",
    "    y_binary = abs_sobel_thresh(img_copy,thresh=(25, 200), orient='y')\n",
    "    xy = cv.bitwise_and(x_binary, y_binary)\n",
    "    \n",
    "    #magnitude & direction\n",
    "    mag_binary = mag_threshold(img_copy, sobel_kernel=3, thresh=(30,100))\n",
    "    dir_binary = dir_threshold(img_copy, sobel_kernel=3, thresh=(0.8, 1.2))\n",
    "    \n",
    "    # Stack each channel\n",
    "    gradient = np.zeros_like(s_binary)\n",
    "    gradient[((x_binary == 1) & (y_binary == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    final_binary = cv.bitwise_or(s_binary, gradient)\n",
    "    \n",
    "    return final_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard,Callback\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 29\n",
    "m = 20\n",
    "\n",
    "i = 0\n",
    "for image in val_samples[:]:\n",
    "    full_img = cv2.imread(image, 1)#[:, 256:, :3]\n",
    "    img_ = full_img[:, :256, :3]\n",
    "#     segmented = full_img[:, 512:, :]\n",
    "    h, w,_ = img_.shape\n",
    "#     img_ = cv2.resize(img_, (512, 512))\n",
    "\n",
    "    tmp = img_[:]\n",
    "#     img_ = cv2.resize(img_, (256, 256))\n",
    "    r_img = img_\n",
    "    img_ = np.float32(img_)/255.0\n",
    "    name = os.path.basename(image)\n",
    "    maskPath = val_masks_path + name#[3:]\n",
    "    gt = cv2.imread(maskPath, -1)\n",
    "    if img_.shape[0] ==(512):\n",
    "        image_list = []\n",
    "        for n in range(0, 512, 256):\n",
    "            for m in range(0, 512, 256):\n",
    "                image_list.append(img_[n:n+256, m:m+256, :])\n",
    "    else:\n",
    "        image_list = [img_]\n",
    "    seg_list = []\n",
    "    name = os.path.basename(image)      \n",
    "    for i, img in enumerate(image_list):\n",
    "#         input_image_gray = data_util.get_image(image,do_aug=[],gray=True, change=False)\n",
    "        input_image_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        w1, w2, w3, w4 = lanenet_wavelet(input_image_gray)\n",
    "        w1 = np.expand_dims(w1, axis=0)\n",
    "        w2 = np.expand_dims(w2, axis=0)\n",
    "        w3 = np.expand_dims(w3, axis=0)\n",
    "        w4 = np.expand_dims(w4, axis=0)\n",
    "\n",
    "        mask = model.predict([np.expand_dims(img, axis=0), w1, w2, w3, w4], batch_size=None, verbose=0, steps=None)\n",
    "        mask = np.round(mask[0, :, :, 0]).astype(int)\n",
    "\n",
    "        seg = np.zeros((256, 256, 3))\n",
    "\n",
    "        seg[:, :, 0] += ((mask[:, :] == 1) * (255)).astype('uint8')\n",
    "        seg[:, :, 1] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "        seg[:, :, 2] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "        seg_list.append(seg)\n",
    "    final_seg = np.zeros((h, w, 3))\n",
    "    for i,seg in enumerate(seg_list):\n",
    "        if i == 0:\n",
    "            final_seg[:256, :256, :] = seg\n",
    "        elif i == 1:\n",
    "            final_seg[:256, 256:, :] = seg\n",
    "        elif i == 3:\n",
    "            final_seg[256:, 256:, :] = seg\n",
    "        else:\n",
    "            final_seg[256:, :256, :] = seg\n",
    "            \n",
    "    dest = new_dir + name\n",
    "#     index = np.all((segmented == np.array((0, 0, 0)).reshape(1, 1, 3)), axis=2)\n",
    "#     final_seg[index] = np.array((0, 0, 0))\n",
    "#         r = 0 if i < 2 else 1\n",
    "#         c = 0 if i % 2 == 0 else 1\n",
    "        \n",
    "#         bigImg[r*256 : (r+1)*256, c*256 : (c+1)*256, :] = img*255\n",
    "#         bigMask[r*256 : (r+1)*256, c*256 : (c+1)*256, :] = seg\n",
    "#         filename = new_dir + name\n",
    "#     seg = cv2.resize(seg, (512, 512))\n",
    "#         cv2.imwrite(filename, np.concatenate((bigImg, bigMask), axis=1))\n",
    "    merge = np.concatenate((full_img, gt, final_seg), axis=1)\n",
    "#         pred_list.append(merge)\n",
    "    cv2.imwrite(dest, merge)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard,Callback\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BigLane = np.zeros_like((BigImg))\n",
    "for r in range(0, BigImg.shape[0], 256):\n",
    "    for c in range(0, BigImg.shape[1], 256):\n",
    "        \n",
    "        img = BigImg[r:r+256, c:c+256, :3]\n",
    "#         h, w, _ = img.shape\n",
    "        tmp = img[:]\n",
    "        img = np.float32(img)/255.0\n",
    "        \n",
    "#         input_image_gray = data_util.get_image(image,do_aug=[],gray=True, change=False)\n",
    "        input_image_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        w1, w2, w3, w4 = lanenet_wavelet(input_image_gray)\n",
    "        w1 = np.expand_dims(w1, axis=0)\n",
    "        w2 = np.expand_dims(w2, axis=0)\n",
    "        w3 = np.expand_dims(w3, axis=0)\n",
    "        w4 = np.expand_dims(w4, axis=0)\n",
    "\n",
    "        mask = model.predict([np.expand_dims(img, axis=0), w1, w2, w3, w4], batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "        mask = np.round(mask[0, :, :, 0]).astype(int)\n",
    "        seg = np.zeros((256, 256, 3))\n",
    "\n",
    "        seg[:, :, 0] += ((mask[:, :] == 1) * (255)).astype('uint8')\n",
    "        seg[:, :, 1] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "        seg[:, :, 2] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "        \n",
    "        BigLane[r:r+256, c:c+256, :] = seg\n",
    "name = 'BigLane2.png' \n",
    "new_dir = './'\n",
    "dest = new_dir + name\n",
    "cv2.imwrite(dest, BigLane)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(BigLane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBackground IOU = %02f\"%BG_IU)\n",
    "print(\"Main-Class IOU = %02f\"%BD_IU)\n",
    "print(\"Mean IOU = %02f\"%((BG_IU + BD_IU)/2))\n",
    "print(\"Background P-Accuracy = %02f\"%BG_P)\n",
    "print(\"Main-Class P-Accuracy = %02f\\n\"%BD_P)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from tensorflow.python.keras import losses\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from util import losses, custom_data_generator, metrics \n",
    "from keras.utils import multi_gpu_model\n",
    "from models import model_loader\n",
    "import datetime\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "# set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "batch_size =30\n",
    "is_train =  False\n",
    "model_name = 'lanenet'\n",
    "image_width,image_height = 256,256\n",
    "channeles = 3\n",
    "checkpoint_name = \"checkpoint_lanenet\"\n",
    "one_hot_label= False\n",
    "data_aug = False\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./checkpoints/%s/\"%(checkpoint_name)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_inputs_path = \"/home/beemap/Documents/noor-workspace/Semantic-Segmentation-Suite/airbus/train/\"\n",
    "# train_masks_path = \"/home/beemap/Documents/noor-workspace/Semantic-Segmentation-Suite/airbus/train_label/\"\n",
    "# val_inputs_path = \"/home/beemap/Documents/noor-workspace/Semantic-Segmentation-Suite/airbus/val/\"\n",
    "# val_masks_path = \"/home/beemap/Documents/noor-workspace/Semantic-Segmentation-Suite/airbus/val_label/\"\n",
    "\n",
    "\n",
    "\n",
    "# train_inputs_path = \"/media/HDD_4T/noor-workspace/airbus-dataset/train/\"\n",
    "# train_masks_path = \"/media/HDD_4T/noor-workspace/airbus-dataset/train_label/\"\n",
    "# val_inputs_path = \"/media/HDD_4T/noor-workspace/airbus-dataset/val/\"\n",
    "# val_masks_path = \"/media/HDD_4T/noor-workspace/airbus-dataset/val_label/\"\n",
    "\n",
    "path = '../LANE_20_All'\n",
    "# train_inputs_path = path + \"/train/\"\n",
    "# train_masks_path = path +\"/train_labels/\"\n",
    "val_inputs_path = path +\"/images/\"\n",
    "val_masks_path = path +\"/val/\"\n",
    "\n",
    " \n",
    "#train_samples = glob.glob(train_inputs_path + \"*.png\")\n",
    "# train_samples = [s for s in train_samples if \"seoul\" in s] + \\\n",
    "#                 [s for s in train_samples if \"suwon\" in s] + \\\n",
    "#                 [s for s in train_samples if \"daegu\" in s]\n",
    " \n",
    "val_samples = glob.glob(val_inputs_path + \"*\")\n",
    "# val_samples = [s for s in val_samples if \"seoul\" in s] + \\\n",
    "#                 [s for s in val_samples if \"suwon\" in s] + \\\n",
    "#                 [s for s in val_samples if \"daegu\" in s]\n",
    "\n",
    "\n",
    "\n",
    "#print(\"\\n\\nTraining samples = %s\"%(len(train_samples)))\n",
    "print(\"Validation samples = %s\\n\\n\"%(len(val_samples)))\n",
    "#train_generator = custom_data_generator.image_generator(train_samples,train_inputs_path,train_masks_path, batch_size,one_hot_label,data_aug)\n",
    "#val_generator = custom_data_generator.image_generator(val_samples,val_inputs_path,val_masks_path,batch_size,one_hot_label)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(val_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(val_samples[0], -1)\n",
    "#img = cv2.resize(img, (256, 256))\n",
    "img.shape\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = './predictions_lanes_20_NEW_2/'\n",
    "if not os.path.isdir(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_train:   \n",
    "    \n",
    "     print(\"Training .....\")\n",
    "\n",
    "else:\n",
    "    print(\"Loading Model .... \",checkpoint_dir)\n",
    "    json_file = open(checkpoint_dir+model_name+\".json\", 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(\"./checkpoints/%s/%s_weights_200.h5\"%(checkpoint_name,model_name))\n",
    "    #asd\n",
    "#     print(checkpoint_path)\n",
    "#     files = glob.glob('/home/beemap/Documents/noor-workspace/Semantic-Segmentation-Suite/airbus/train/*.png')\n",
    "#     accu = []\n",
    "#     BG_IU, BD_IU, BG_P, BD_P = metrics.calculate_IoU_Per_Epoch(model,val_inputs_path,val_masks_path,checkpoint_dir,1,False)\n",
    "#     for i in range(50):\n",
    "#         gen = next(train_generator)\n",
    "#     gen = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import abs_sobel_thresh\n",
    "from processing import mag_threshold\n",
    "from processing import *\n",
    "from util import custom_data_generator as data_util\n",
    "from models.common import lanenet_wavelet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_pipeline(img, mask):\n",
    "    \n",
    "    ind = (mask == 0)\n",
    "    img[ind] = 0\n",
    "    img_copy = cv.GaussianBlur(img, (3, 3), 0)\n",
    "    #img_copy = np.copy(img)\n",
    "    \n",
    "    # color channels\n",
    "    s_binary = hls_select(img_copy, sthresh=(140, 255), lthresh=(120, 255))\n",
    "    #red_binary = red_select(img_copy, thresh=(200,255))\n",
    "    \n",
    "    # Sobel x\n",
    "    x_binary = abs_sobel_thresh(img_copy,thresh=(25, 200))\n",
    "    y_binary = abs_sobel_thresh(img_copy,thresh=(25, 200), orient='y')\n",
    "    xy = cv.bitwise_and(x_binary, y_binary)\n",
    "    \n",
    "    #magnitude & direction\n",
    "    mag_binary = mag_threshold(img_copy, sobel_kernel=3, thresh=(30,100))\n",
    "    dir_binary = dir_threshold(img_copy, sobel_kernel=3, thresh=(0.8, 1.2))\n",
    "    \n",
    "    # Stack each channel\n",
    "    gradient = np.zeros_like(s_binary)\n",
    "    gradient[((x_binary == 1) & (y_binary == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    final_binary = cv.bitwise_or(s_binary, gradient)\n",
    "    \n",
    "    return final_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard,Callback\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 29\n",
    "m = 20\n",
    "#_, ax = plt.subplots(m, 4, figsize=(20, 50))\n",
    "\n",
    "# if is_train:   \n",
    "    \n",
    "#      print(\"Training .....\")\n",
    "\n",
    "# else:\n",
    "#     print(\"Loading Model .... \",checkpoint_dir)\n",
    "#     json_file = open(checkpoint_dir+model_name+\".json\", 'r')\n",
    "#     loaded_model_json = json_file.read()\n",
    "#     json_file.close()\n",
    "#     model = model_from_json(loaded_model_json)\n",
    "#     model.load_weights(\"./checkpoints/%s/%s_weights_40.h5\"%(checkpoint_name,model_name))\n",
    "    #asd\n",
    "#     print(checkpoint_path)\n",
    "#     files = glob.glob('/home/beemap/Documents/noor-workspace/Semantic-Segmentation-Suite/airbus/train/*.png')\n",
    "#     accu = []\n",
    "#     BG_IU, BD_IU, BG_P, BD_P = metrics.calculate_IoU_Per_Epoch(model,val_inputs_path,val_masks_path,checkpoint_dir,1,False)\n",
    "#     for i in range(50):\n",
    "#         gen = next(train_generator)\n",
    "#     gen = next(train_generator)\n",
    "i = 0\n",
    "for image in val_samples[:]:\n",
    "    #gen = next(val_generator)\n",
    "    #x = gen[0]\n",
    "    #y = gen[1]\n",
    "    img = cv2.imread(image, -1)[:, :, :3]\n",
    "    #img = cv2.resize(img, (256, 256))\n",
    "    r_img = img\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    #print(img.shape)\n",
    "    img = np.float32(img)/255.0\n",
    "    name = os.path.basename(image)\n",
    "    maskPath = val_masks_path + name#[3:]\n",
    "#     if not os.path.isfile(maskPath):\n",
    "#         continue\n",
    "#     gt = cv2.imread(maskPath, -1)\n",
    "    #gt = cv2.resize(gt, (256, 256))\n",
    "    #print(img.shape)\n",
    "    input_image_gray = data_util.get_image(image,do_aug=[],gray=True, change=False)\n",
    "    input_image_gray = cv2.resize(input_image_gray, (256, 256))\n",
    "    \n",
    "    w1, w2, w3, w4 = lanenet_wavelet(input_image_gray)\n",
    "    w1 = np.expand_dims(w1, axis=0)\n",
    "    w2 = np.expand_dims(w2, axis=0)\n",
    "    w3 = np.expand_dims(w3, axis=0)\n",
    "    w4 = np.expand_dims(w4, axis=0)\n",
    "    mask = model.predict([np.expand_dims(img, axis=0), w1, w2, w3, w4], batch_size=None, verbose=0, steps=None)\n",
    "    #print(mask.shape)\n",
    "    mask = np.round(mask[0, :, :, 0]).astype(int)\n",
    "    #print(mask.shape)\n",
    "    seg = np.zeros((256, 256, 3))\n",
    "    #print((mask.shape))\n",
    "    #for c in range(3):\n",
    "    seg[:, :, 0] += ((mask[:, :] == 1) * (255)).astype('uint8')\n",
    "    seg[:, :, 1] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "    seg[:, :, 2] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "\n",
    "    #mask = model.predict(img, batch_size=None, verbose=0, steps=1)\n",
    "#     filename = new_dir + name[:-4] + '_pred' + '.png'\n",
    "#     gt_name = val_masks_path + name[3:]\n",
    "#     gt_dst = new_dir + name[:-4] + '_gt' + '.png'\n",
    "    #gt_img = cv2.imread(gt_name, -1)\n",
    "\n",
    "    #print(filename)\n",
    "    #cv2.imwrite(filename, seg)\n",
    "    #cv2.imwrite(gt_dst, gt_img)\n",
    "    name = os.path.basename(image)\n",
    "    dest = new_dir + name\n",
    "    result = binary_pipeline(img, mask)\n",
    "    #if np.any(mask == 1):\n",
    "    #shutil.copy(gt_name, gt_dst)\n",
    "#         img = cv2.resize(img, (512, 512))\n",
    "#         print(mask.shape)\n",
    "#         mask = cv2.resize(mask, (512, 512))\n",
    "#         result = cv2.resize(result, (512, 512))\n",
    "    #new_res = np.concatenate((r_img, seg),axis=1)\n",
    "    seg = cv2.resize(seg, (512, 512))\n",
    "    \n",
    "    cv2.imwrite(dest, seg)\n",
    "#     ax[i, 0].imshow(img)\n",
    "#     ax[i, 1].imshow(result)\n",
    "#     ax[i, 2].imshow(seg)\n",
    "#     ax[i, 3].imshow(r_img)\n",
    "\n",
    "#         #plt.imshow(abs_sobel_thresh(image, thresh=(20,110)),  cmap='gray');\n",
    "#         #result = binary_pipeline(image)\n",
    "    i+=1\n",
    "    #if i >= m:\n",
    "        #break\n",
    "    #shutil.copy(image, dest)\n",
    "    #print(mask.shape)\n",
    "# #         thr = 0.5 \n",
    "# #         mask[mask >= thr] = 1\n",
    "# #         mask[mask < 1] = 0\n",
    "#         gt = np.reshape(np.argmax(y, axis=-1), (10,256 , 256))\n",
    "#         pr = np.reshape(np.argmax(mask, axis=-1), (10,256 , 256))\n",
    "\n",
    "#         overlap = np.array(gt,dtype=bool)*np.array(pr,dtype=bool)\n",
    "#         union = np.array(gt,dtype=bool) + np.array(pr,dtype=bool)\n",
    "#         IOU = overlap.sum()/float(union.sum())\n",
    "#         accu.append(IOU)\n",
    "#         print(IOU)\n",
    "\n",
    "#     f, axarr = plt.subplots(batch_size,3,figsize=(20,50))\n",
    "#     for j in range(batch_size):\n",
    "#         axarr[j,0].imshow(x[j,:,:,:])\n",
    "#         axarr[j,1].imshow(y[j,:,:,0])\n",
    "#         axarr[j,2].imshow(np.round(mask[j,:,:,0]))\n",
    "#         axarr[1,0].imshow(x[1,:,:,:])\n",
    "#         axarr[1,1].imshow(y[1,:,:,0])\n",
    "#         axarr[1,2].imshow(mask[1,:,:,0])\n",
    "#         axarr[2,0].imshow(x[2,:,:,:])\n",
    "#         axarr[2,1].imshow(y[2,:,:,0])\n",
    "#         axarr[2,2].imshow(mask[2,:,:,0])\n",
    "\n",
    "\n",
    "#     overlap = np.array(y[:,:,:,0],dtype=bool)*np.array(np.round(mask[:,:,:,0]),dtype=bool)\n",
    "#     union = np.array(y[:,:,:,0],dtype=bool) + np.array(np.round(mask[:,:,:,0]),dtype=bool)\n",
    "#     IOU = overlap.sum()/float(union.sum())\n",
    "#     print(IOU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = (mask==1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = next(val_generator)\n",
    "x = gen[0]\n",
    "y = gen[1]\n",
    "f, axarr = plt.subplots(batch_size,3,figsize=(20,50))\n",
    "for j in range(batch_size):\n",
    "    axarr[j,0].imshow(x[j,:,:,:])\n",
    "    axarr[j,1].imshow(y[j,:,:,0])\n",
    "    axarr[j,2].imshow(y[j,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y[j,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "BG_IU, BD_IU, BG_P, BD_P = calculate_IoU_Per_Epoch(model,val_inputs_path,val_masks_path,\"./checkpoints/%s/\"%(checkpoint_name),11,one_hot_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG_IU, BD_IU, BG_P, BD_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y[14,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from util import custom_data_generator as data_util\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "def calculate_IoU_Per_Epoch(model,val_inputs_path,val_masks_path,checkpoint_path,epoch_number,one_hot_label=False):\n",
    "    \n",
    "    val_samples = [os.path.basename(x) for x in glob.glob(val_inputs_path + \"*.png\")]\n",
    "#     val_samples = [s for s in val_samples if \"seoul\" in s] + \\\n",
    "#                 [s for s in val_samples if \"suwon\" in s] + \\\n",
    "#                 [s for s in val_samples if \"daegu\" in s]\n",
    "    val_samples_mini = val_samples[0:15] #+ val_samples[2000:2015]\n",
    "\n",
    "    \n",
    "    save_path = \"%s/epoch_%s/\"%(checkpoint_path,epoch_number)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    IU_BG_TP,IU_BG_FN,IU_BG_FP,IU_BG_TN,IU_BD_TP,IU_BD_FN,IU_BD_FP,IU_BD_TN=[],[],[],[],[],[],[],[]\n",
    "    for j in range(len(val_samples_mini)):\n",
    "        img = val_samples_mini[j]\n",
    "#         print(img)\n",
    "        \n",
    "        gt =  data_util.get_mask(val_masks_path+img,one_hot_label=one_hot_label,do_aug=[])[:,:,0].astype(int) \n",
    "        input_image = data_util.get_image(val_inputs_path+img,do_aug=[])\n",
    "        pred = model.predict(np.expand_dims(input_image, axis=0), batch_size=None, verbose=0, steps=None)\n",
    "        \n",
    "        \n",
    "        if one_hot_label:\n",
    "            pred = np.reshape(pred, (256 , 256, 2))\n",
    "            pred = np.argmax(pred, axis=-1).astype(int) \n",
    "        else:\n",
    "            pred = np.round(pred[0,:,:,0]).astype(int)      #(pred *255).astype(int)\n",
    "        \n",
    "        classes = np.array([0, 1])\n",
    "        \n",
    "        for ii in classes:\n",
    "            \n",
    "            TP, FN, FP, TN = IoU(pred, gt, ii)\n",
    "            \n",
    "            if ii == 0:\n",
    "                IU_BG_TP.append(TP)\n",
    "                IU_BG_FN.append(FN)\n",
    "                IU_BG_FP.append(FP)\n",
    "                IU_BG_TN.append(TN)\n",
    "\n",
    "            elif ii == 1:\n",
    "                print(TP, FN, FP, TN,ii)\n",
    "                IU_BD_TP.append(TP)\n",
    "                IU_BD_FN.append(FN)\n",
    "                IU_BD_FP.append(FP)\n",
    "                IU_BD_TN.append(TN)\n",
    "        gt_pred = np.concatenate((data_util.changelabels(gt,'1d2rgb'),data_util.changelabels(pred,'1d2rgb')),axis=1) \n",
    "        cv2.imwrite(save_path+img,np.concatenate((input_image*255,gt_pred),axis=1))\n",
    "#         break\n",
    "\n",
    "    print(IU_BD_TP,IU_BD_FN,IU_BD_FP)\n",
    "    BG_IU = 100 * divided_IoU(IU_BG_TP, IU_BG_FN, IU_BG_FP)\n",
    "    BD_IU = 100 * divided_IoU(IU_BD_TP, IU_BD_FN, IU_BD_FP)\n",
    "    BG_P = 100 * divided_PixelAcc(IU_BG_TP, IU_BG_FN)\n",
    "    BD_P = 100 * divided_PixelAcc(IU_BD_TP, IU_BD_FN)\n",
    "    \n",
    "    return BG_IU, BD_IU, BG_P, BD_P \n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "def IoU(pred, valid, cl):\n",
    "    tp = np.count_nonzero(np.logical_and(pred == cl, valid == cl))\n",
    "    fn = np.count_nonzero(np.logical_and(pred != cl, valid == cl))\n",
    "    fp = np.count_nonzero(np.logical_and(pred == cl, valid != cl))\n",
    "    tn = np.count_nonzero(np.logical_and(pred != cl, valid != cl))\n",
    "    return tp, fn, fp, tn\n",
    "\n",
    "\n",
    "def divided_IoU(tp, fn, fp):\n",
    "    try:\n",
    "        return float(sum(tp)) / (sum(tp) + sum(fn) + sum(fp))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def divided_PixelAcc(tp, fn):\n",
    "    try:\n",
    "        return float(sum(tp)) / (sum(tp) + sum(fn))\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BG_IU, BD_IU, BG_P, BD_P = calculate_IoU_Per_Epoch(model,val_inputs_path,val_masks_path,\"./checkpoints/%s/\"%(checkpoint_name),11,one_hot_label=False)\n",
    "    \n",
    "print(\"\\nBackground IOU = %02f\"%BG_IU)\n",
    "print(\"Main-Class IOU = %02f\"%BD_IU)\n",
    "print(\"Mean IOU = %02f\"%((BG_IU + BD_IU)/2))\n",
    "print(\"Background P-Accuracy = %02f\"%BG_P)\n",
    "print(\"Main-Class P-Accuracy = %02f\\n\"%BD_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, axarr = plt.subplots(1,3,figsize=(10,50))\n",
    "\n",
    "j = 3\n",
    "# axarr[j,0].imshow(x[j,:,:,:])\n",
    "# plt.imshow()\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plt.imshow(np.concatenate((y[j,:,:,0],np.round(mask[j,:,:,0])),axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_generator = custom_data_generator.image_generator(val_samples,val_inputs_path,val_masks_path,  batch_size,False)\n",
    "\n",
    "gen = next(val_generator)\n",
    "gen = next(val_generator)\n",
    "x = gen[0]\n",
    "y = gen[1]\n",
    "mask = model.predict(x, batch_size=None, verbose=0, steps=None)\n",
    "f, axarr = plt.subplots(batch_size,3,figsize=(20,50))\n",
    "for j in range(10):\n",
    "    axarr[j,0].imshow(x[j,:,:,:])\n",
    "    axarr[j,1].imshow(y[j,:,:,0])\n",
    "    axarr[j,2].imshow(mask[j,:,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = np.array(gt,dtype=bool)*np.array(pr,dtype=bool)\n",
    "union = np.array(gt,dtype=bool) + np.array(pr,dtype=bool)\n",
    "IOU = overlap.sum()/float(union.sum())\n",
    "accu.append(IOU)\n",
    "print(IOU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import custom_data_generator as data_util\n",
    "img = '18_44950_104646.png'\n",
    "gt =  data_util.get_mask(val_masks_path+img)[:,:,0]\n",
    "input_image = data_util.get_image(val_inputs_path+img)\n",
    "input_image = np.expand_dims(input_image, axis=0)\n",
    "print(gt.dtype)\n",
    "# mask = model.predict(input_image, batch_size=None, verbose=0, steps=None)\n",
    "plt.imshow(gt[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(labels_dir, label_values):\n",
    "    '''\n",
    "    Arguments:\n",
    "        labels_dir(list): Directory where the image segmentation labels are\n",
    "        num_classes(int): the number of classes of pixels in all images\n",
    "\n",
    "    Returns:\n",
    "        class_weights(list): a list of class weights where each index represents each class label and the element is the class weight for that label.\n",
    "\n",
    "    '''\n",
    "    image_files = [os.path.join(labels_dir, file) for file in os.listdir(labels_dir) if file.endswith('.png')]\n",
    "    num_classes = len(label_values)\n",
    "    class_pixels = np.zeros(num_classes)\n",
    "    total_pixels = 0.0\n",
    "    for n in range(len(image_files)):\n",
    "        image = imread(image_files[n], mode=\"RGB\")\n",
    "        for index, colour in enumerate(label_values):\n",
    "            class_map = np.all(np.equal(image, colour), axis = -1)\n",
    "            class_map = class_map.astype(np.float32)\n",
    "            class_pixels[index] += np.sum(class_map)\n",
    "\n",
    "        print(\"\\rProcessing image: \" + str(n) + \" / \" + str(len(image_files)), end=\"\")\n",
    "        sys.stdout.flush()\n",
    "    total_pixels = float(np.sum(class_pixels))\n",
    "    index_to_delete = np.argwhere(class_pixels==0.0)\n",
    "    class_pixels = np.delete(class_pixels, index_to_delete)\n",
    "    class_weights = total_pixels / class_pixels\n",
    "    class_weights = class_weights / np.sum(class_weights)\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import sys\n",
    "res=compute_class_weights(\"/media/HDD_4T/Documents/cesar-workspace/lashan/train_labels/\",[(0,0,0),(0,255,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBackground IOU = %02f\"%BG_IU)\n",
    "print(\"Main-Class IOU = %02f\"%BD_IU)\n",
    "print(\"Mean IOU = %02f\"%((BG_IU + BD_IU)/2))\n",
    "print(\"Background P-Accuracy = %02f\"%BG_P)\n",
    "print(\"Main-Class P-Accuracy = %02f\\n\"%BD_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(img, axis=-1)\n",
    "pred = np.reshape(pred, (256 , 256))\n",
    "plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BG_IU, BD_IU, BG_P, BD_P = metrics.calculate_IoU_Per_Epoch(model,val_inputs_path,val_masks_path,checkpoint_dir,1,False)\n",
    "overlap = np.array(y[:,:,:,0],dtype=bool)*np.array(np.round(mask[:,:,:,0]),dtype=bool)\n",
    "union = np.array(y[:,:,:,0],dtype=bool) + np.array(np.round(mask[:,:,:,0]),dtype=bool)\n",
    "IOU = overlap.sum()/float(union.sum())\n",
    "print(IOU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, axarr = plt.subplots(batch_size,2,figsize=(30,50))\n",
    "for j in range(40):\n",
    "    scipy.misc.toimage(np.concatenate((y[j,:,:,0],mask[j,:,:,0]),axis=1), cmin=0.0, cmax=1).save(\"./pred/%s.png\"%j)\n",
    "#     cv2.imwrite(\"./pred/%s.png\"%j,np.concatenate((y[j,:,:,0].astype(int),mask[j,:,:,0].astype(int)),axis=1))\n",
    "#     axarr[j,0].imshow(x[j,:,:,:])\n",
    "#     axarr[j,0].imshow(y[j,:,:,0])\n",
    "#     axarr[j,1].imshow(mask[j,:,:,0])\n",
    "plt.imshow(np.concatenate((y[1,:,:,0].astype(int),mask[1,:,:,0].astype(int)),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[1,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "scipy.misc.toimage(mask[0,:,:,0], cmin=0.0, cmax=1).save('outfile.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "f, axarr = plt.subplots(3,3,figsize=(50,50))\n",
    "axarr[0,0].imshow(x[0,:,:,:])\n",
    "axarr[0,1].imshow(y[0,:,:,0])\n",
    "axarr[0,2].imshow(mask[0,:,:,0])\n",
    "axarr[1,0].imshow(x[1,:,:,:])\n",
    "axarr[1,1].imshow(y[1,:,:,0])\n",
    "axarr[1,2].imshow(mask[1,:,:,0])\n",
    "axarr[2,0].imshow(x[2,:,:,:])\n",
    "axarr[2,1].imshow(y[2,:,:,0])\n",
    "axarr[2,2].imshow(mask[2,:,:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.round(mask[1,:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat = x[0,:,:,:]\n",
    "pred = mask[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = cv2.watershed(sat,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/beemap/miniconda3/envs/cesar3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/beemap/miniconda3/envs/cesar3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/beemap/miniconda3/envs/cesar3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/beemap/miniconda3/envs/cesar3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/beemap/miniconda3/envs/cesar3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/beemap/miniconda3/envs/cesar3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from tensorflow.python.keras import losses\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from util import losses, custom_data_generator, metrics \n",
    "from keras.utils import multi_gpu_model\n",
    "from models import model_loader\n",
    "import datetime\n",
    "from processing import abs_sobel_thresh\n",
    "from processing import mag_threshold\n",
    "from processing import *\n",
    "from util import custom_data_generator as data_util\n",
    "from models.common import lanenet_wavelet\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "# set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "batch_size =30\n",
    "is_train =  False\n",
    "# model_name = 'lanenet'\n",
    "image_width,image_height = 256,256\n",
    "channeles = 3\n",
    "# checkpoint_name = \"checkpoint_lanenet\"\n",
    "one_hot_label= False\n",
    "data_aug = False\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples = 8927\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/home/beemap/Documents/cesar-workspace/Lane_Data/Mix_dataset_full'\n",
    "val_inputs_path = path +\"/train/\"\n",
    "val_masks_path = path +\"/train_labels/\"\n",
    "\n",
    "\n",
    "val_samples = glob.glob(val_inputs_path + \"*\")\n",
    "\n",
    "print(\"Validation samples = %s\\n\\n\"%(len(val_samples)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigImg = './full_img.png'\n",
    "bigLane = './BigLane.png'\n",
    "BigImg = cv2.imread(bigImg, -1)\n",
    "BigLane = cv2.imread(bigLane, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4608, 5120, 3), (4608, 5120, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BigImg.shape, BigLane.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model ....  ./checkpoints/GAN_v4_label_normal_lanenet2/\n"
     ]
    }
   ],
   "source": [
    "checkpoint_name = \"GAN_v4_label_normal_lanenet2\"\n",
    "model_name = 'lanenet2'\n",
    "checkpoint_dir = \"./checkpoints/%s/\"%(checkpoint_name)\n",
    "\n",
    "\n",
    "print(\"Loading Model .... \",checkpoint_dir)\n",
    "json_file = open(checkpoint_dir+model_name+\".json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"./checkpoints/%s/%s_weights_90.h5\"%(checkpoint_name,model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = './predictions_lanes_lines_v5/'\n",
    "if not os.path.isdir(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hough_lines(img, rho=1, theta=np.pi/180, threshold=20, min_line_len=20, max_line_gap=300):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), \n",
    "                            minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    return lines\n",
    "def draw_lines(img, lines, color=[255, 255, 255], thickness=1):\n",
    "    \n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        img = np.stack([img] * 3, axis=-1)\n",
    "    if (type(lines) != np.ndarray):\n",
    "        return img\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "    return img\n",
    "\n",
    "def grayscale(img):\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "def hough_lines(img, rho=1, min_line_len=13,threshold=70, max_line_gap=300):\n",
    "#     img = grayscale(img)\n",
    "#     print(img.shape)\n",
    "    edges = cv2.Canny(img, 80, 200)\n",
    "    hough = get_hough_lines(edges, rho=rho, min_line_len=min_line_len, threshold=threshold, max_line_gap=max_line_gap)\n",
    "    canvas = np.zeros_like(img)\n",
    "    return draw_lines(canvas, hough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard,Callback\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 29\n",
    "m = 20\n",
    "\n",
    "i = 0\n",
    "for image in val_samples[:]:\n",
    "    full_img = cv2.imread(image, 1)#[:, 256:, :3]\n",
    "    img_ = full_img[:, :, :3]\n",
    "#     segmented = full_img[:, 512:, :]\n",
    "    h, w,_ = img_.shape\n",
    "#     lane = \n",
    "    tmp = img_[:]\n",
    "    r_img = img_\n",
    "\n",
    "    img_ = np.float32(img_)/255.0\n",
    "    name = os.path.basename(image)\n",
    "    maskPath = val_masks_path + name#[3:]\n",
    "    lane = cv2.imread(maskPath, -1)/255.0\n",
    "    lane_gray = cv2.imread(maskPath, 0)\n",
    "    hough = hough_lines(lane_gray, rho=1, min_line_len=10,threshold=40, max_line_gap=300)/255.0\n",
    "    lane += hough\n",
    "#     lane/=255.0\n",
    "    img_ = np.concatenate((img_, lane), axis=1)\n",
    "#     print(img_.shape)\n",
    "    if img_.shape[0] ==(512):\n",
    "        image_list = []\n",
    "        for n in range(0, 512, 256):\n",
    "            for m in range(0, 512, 256):\n",
    "                image_list.append(img_[n:n+256, m:m+256, :])\n",
    "    else:\n",
    "        image_list = [img_]\n",
    "    seg_list = []\n",
    "    name = os.path.basename(image)      \n",
    "    for i, img in enumerate(image_list):\n",
    "#         input_image_gray = data_util.get_image(image,do_aug=[],gray=True, change=False)\n",
    "        \n",
    "        img0 = img[:, :256, :]\n",
    "        img1 = img[:, 256:, :]\n",
    "#         print(img0.shape)\n",
    "        input_image_gray = cv2.imread(image, 0)#cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)\n",
    "        w1, w2, w3, w4 = lanenet_wavelet(input_image_gray)\n",
    "        w1 = np.expand_dims(w1, axis=0)\n",
    "        w2 = np.expand_dims(w2, axis=0)\n",
    "        w3 = np.expand_dims(w3, axis=0)\n",
    "        w4 = np.expand_dims(w4, axis=0)\n",
    "#         print(img.shape)\n",
    "        mask = model.predict([np.expand_dims(img0, axis=0), np.expand_dims(img1, axis=0), w1, w2, w3, w4], batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "#         mask = model.predict([np.expand_dims(img, axis=0), w1, w2, w3, w4], batch_size=None, verbose=0, steps=None)\n",
    "        #print(mask.shape)\n",
    "        mask = np.round(mask[0, :, :, 0]).astype(int)\n",
    "        #print(mask.shape)\n",
    "        seg = np.zeros((256, 256, 3))\n",
    "\n",
    "        seg[:, :, 0] += ((mask[:, :] == 1) * (255)).astype('uint8')\n",
    "        seg[:, :, 1] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "        seg[:, :, 2] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "        seg_list.append(seg)\n",
    "    final_seg = np.zeros((h, w, 3))\n",
    "    for i,seg in enumerate(seg_list):\n",
    "        if i == 0:\n",
    "            final_seg[:256, :256, :] = seg\n",
    "        elif i == 1:\n",
    "            final_seg[:256, 256:, :] = seg\n",
    "        elif i == 3:\n",
    "            final_seg[256:, 256:, :] = seg\n",
    "        else:\n",
    "            final_seg[256:, :256, :] = seg\n",
    "            \n",
    "            \n",
    "#         pred_list.append(seg)\n",
    "    dest = new_dir + name#[:-4] + '_' + '.png'\n",
    "#     index = np.all((segmented == np.array((0, 0, 0)).reshape(1, 1, 3)), axis=2)\n",
    "#     final_seg[index] = np.array((0, 0, 0))\n",
    "#         r = 0 if i < 2 else 1\n",
    "#         c = 0 if i % 2 == 0 else 1\n",
    "        \n",
    "#         bigImg[r*256 : (r+1)*256, c*256 : (c+1)*256, :] = img*255\n",
    "#         bigMask[r*256 : (r+1)*256, c*256 : (c+1)*256, :] = seg\n",
    "#         filename = new_dir + name\n",
    "#     seg = cv2.resize(seg, (512, 512))\n",
    "#         cv2.imwrite(filename, np.concatenate((bigImg, bigMask), axis=1))\n",
    "    merge = np.concatenate((img0*255, img1*255, final_seg), axis=1)\n",
    "#         pred_list.append(merge)\n",
    "    cv2.imwrite(dest, merge)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigLane_gray = cv2.imread(bigLane, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard,Callback\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BigLine = np.zeros_like((BigImg))\n",
    "\n",
    "for r in range(0, BigImg.shape[0], 256):\n",
    "    for c in range(0, BigImg.shape[1], 256):\n",
    "        img = BigImg[r:r+256, c:c+256, :3]\n",
    "#         h, w, _ = img.shape\n",
    "        tmp = img[:]\n",
    "        lane = BigLane[r:r+256, c:c+256, :3]\n",
    "        img = np.float32(img)/255.0\n",
    "        lane = np.float32(lane)/255.0\n",
    "        \n",
    "#         input_image_gray = data_util.get_image(image,do_aug=[],gray=True, change=False)\n",
    "        input_image_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        w1, w2, w3, w4 = lanenet_wavelet(input_image_gray)\n",
    "        w1 = np.expand_dims(w1, axis=0)\n",
    "        w2 = np.expand_dims(w2, axis=0)\n",
    "        w3 = np.expand_dims(w3, axis=0)\n",
    "        w4 = np.expand_dims(w4, axis=0)\n",
    "        lane_gray = BigLane_gray[r:r+256, c:c+256]\n",
    "#         lane_gray = cv2.cvtColor(lane, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        hough = hough_lines(lane_gray, rho=1, min_line_len=10,threshold=40, max_line_gap=300)/255.0\n",
    "        mask = model.predict([np.expand_dims(img, axis=0), np.expand_dims(lane, axis=0), w1, w2, w3, w4], batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "        mask = np.round(mask[0, :, :, 0]).astype(int)\n",
    "        seg = np.zeros((256, 256, 3))\n",
    "\n",
    "        seg[:, :, 0] += ((mask[:, :] == 1) * (255)).astype('uint8')\n",
    "        seg[:, :, 1] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "        seg[:, :, 2] += ((mask[:, :] == 1) * ( 255)).astype('uint8')\n",
    "        \n",
    "        BigLine[r:r+256, c:c+256, :] = seg\n",
    "name = 'BigLine2.png' \n",
    "new_dir = './'\n",
    "dest = new_dir + name\n",
    "cv2.imwrite(dest, BigLine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
